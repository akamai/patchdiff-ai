{'patch_store_uid': '230e7c66-244b-4041-b166-2157fff153a1', 'confidence': 0.25, 'cve': 'CVE-2025-49762', 'file': 'afd.sys', 'kb': 'KB5063878', 'date': 1755089264.6341386, 'change_count': 8}
--------------------------------------------------------------------
CVE-2025-49762 Report
--------------------------------------------------------------------

Component
--------------------------------------------------------------------
Windows kernel-mode driver AFD.SYS (Ancillary Function Driver for
WinSock).


Vulnerability Class
--------------------------------------------------------------------
Race condition (CWE-362) leading to use-after-free / stale pointer
access and ultimately local elevation of privilege.


Detailed Root Cause Analysis
--------------------------------------------------------------------
AFD sockets keep per-endpoint structures that contain pointers to the
current local address, transport handles, connection objects, etc.
Several IOCTL paths copy those fields to user-supplied buffers or call
transport routines while another thread may concurrently detach (unbind)
or replace the very same fields.

1. AfdGetAddress / AfdExtractAfdSendMsgInfo
   • Pre-patch the functions read *Endpoint->LocalAddr* or the pointer
     stored at Endpoint+0xA8/0xF0, then immediately memmove() that
     data to the caller without holding any synchronisation primitive.
   • If another thread executes AfdUnBindSocket or a TL close sequence
     in parallel, the address buffer is freed and the pointer is
     zeroed.  The first thread continues to dereference the freed
     memory, producing a use-after-free and arbitrary kernel read or
     write depending on the IOCTL.

2. AfdUnBindSocket
   • The unbind path itself could run while other threads were still
     using the address/transport fields because the only protection was
     an interlocked state field (Endpoint+0x168).  No global or per
     endpoint lock was taken, so unbind could win the race, free the
     storage and close handles.

3. TL creation / completion paths
   • AfdTLCreateEndpointComplete tried to cache the compartment ID only
     when an optional feature switch was enabled.  Missing caching
     caused another window where the endpoint structure was partially
     initialised but already visible to user operations.

Patch changes
-------------
• Consistent use of KeAcquireInStackQueuedSpinLock() on the endpoint
  spinlock (offset +0x38) before any dereference of the address block
  and related length field, and a re-check after the lock is obtained.

• AfdGetAddress / AfdExtractAfdSendMsgInfo now
    - take the lock,
    - verify that the buffer length still matches,
    - copy only while still holding the lock,
    - release the lock afterwards.

• AfdUnBindSocket now
    - rejects unbind for raw/connected endpoints earlier,
    - denies unbind if Feature flags forbid it,
    - performs TL close only when the new transport pointer is valid,
    - leaves the endpoint in a consistent state before freeing memory.

• AfdTLCreateEndpointComplete removes the feature gate – compartment
  caching is now unconditional and done while holding the global
  resource, guaranteeing that FsContext+0x58 is valid before the
  endpoint becomes usable.

The absence of these locks in the original code allowed two CPU cores
(or user / APC interactions) to operate on the same endpoint and reach
freed memory.  Because the freed pool can be re-used by the attacker,
this results in controlled kernel pointer dereferences and privilege
escalation.


Vulnerability Code Snippets
--------------------------------------------------------------------
```c
// pre-patch AfdExtractAfdSendMsgInfo (excerpt)
if ((*(_DWORD *)(ep+8) & 0x100)==0 && *(_BYTE *)(ep+2)==4 && !Src)
    Size = *(_DWORD *)(ep+164);
memmove(dst, *(void **)(ep+168), Size); // <-- no lock, ep may change
```

```c
// patched version
KeAcquireInStackQueuedSpinLock((PKSPIN_LOCK)(ep+56), &Lock);
if (Size != *(_DWORD *)(ep+164)) { ...fail... }
memmove(dst, *(void **)(ep+168), Size);
KeReleaseInStackQueuedSpinLock(&Lock);
```

```c
// pre-patch AfdUnBindSocket : unbind even though readers still exist
ExFreePoolWithTag(*(PVOID *)(ep+240), 'AdlF');
*(_QWORD *)(ep+240)=0;
...
```

```c
// patched AfdUnBindSocket
if (FeatureX && refcount!=0) {/* deny */}
...
KeResetEvent(&Evt);
vCloseReq[0]=AfdSynchronousTlCloseRequestComplete;
if ((*OldVtab)(OldHandle,vCloseReq)==STATUS_PENDING)
    KeWaitForSingleObject(...);
```


Trigger Flow (Top-Down)
--------------------------------------------------------------------
1. Thread A
   • socket = WSASocket();
   • DeviceIoControl(afd, IOCTL_AFD_GET_ADDRESS, ...)
2. Thread B (parallel)
   • DeviceIoControl(afd, IOCTL_AFD_UNBIND, ...)
3. B wins race, frees Endpoint->LocalAddr and clears pointer.
4. A continues in AfdGetAddress, dereferences freed pointer and copies
   stale or attacker-controlled pool data into user buffer or into
   kernel structures ⇒ memory corruption ⇒ privilege escalation.


Attack Vector
--------------------------------------------------------------------
Local, authenticated user that can obtain a socket handle and issue
AFD IOCTLs can start two or more threads to trigger the race.  No
special privileges are required beyond owning the socket.


Patch Description
--------------------------------------------------------------------
1. Added spin-lock protection around every read/write of endpoint
   address/transport pointers (KeAcquireInStackQueuedSpinLock /
   KeRelease...).
2. Re-validated length and state after the lock (TOCTOU fix).
3. Hardened unbind:
   • extra state checks, feature-flag gating, improved error paths.
   • closes transport handles only after the new handle is installed.
4. Removed conditional compilation for endpoint-compartment caching –
   now always initialised under the global resource.
5. Large defensive clean-up: reference counting, zeroing pointers,
   resetting events, using _InterlockedAdd instead of direct decrements.


Security Impact
--------------------------------------------------------------------
Prior to the patch, a local attacker could achieve elevation of
privilege (ring-0 code execution) by exploiting the race to perform a
use-after-free and craft fake pool objects.  The bug is therefore rated
as an EoP vulnerability in the Windows kernel.


Fix Effectiveness
--------------------------------------------------------------------
The added locking removes the race window: readers cannot access the
address/transport fields while unbind is completing, and length is
re-checked before copy.  Combined with stricter state validation, the
original concurrency issue is effectively mitigated.  No residual race
paths were observed in the patched code.
