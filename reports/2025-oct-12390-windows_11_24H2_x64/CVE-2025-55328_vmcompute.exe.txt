{'patch_store_uid': '07663ad0-52a2-4018-be0d-63fb1362ba50', 'kb': 'KB5066835', 'date': 1763407747.4307406, 'change_count': 11, 'confidence': 0.14, 'cve': 'CVE-2025-55328', 'file': 'vmcompute.exe'}
--------------------------------------------------------------------
CVE-2025-55328 Report
--------------------------------------------------------------------

Component
--------------------------------------------------------------------
Windows Hyper-V / vmcompute.exe – Virtual NUMA and memory-balancer
code that maps virtual processors (VP) to physical logical
processors (LP) and keeps per-node accounting in
GlobalMemoryBalancer::Resource[Info] structures.

Vulnerability Class
--------------------------------------------------------------------
CWE-362: Concurrent execution using shared resource with improper
synchronisation (race condition).

Detailed Root Cause Analysis
--------------------------------------------------------------------
Several helper routines update shared
GlobalMemoryBalancer::Resource objects that are stored in a gsl::span
array and are accessed by multiple worker threads while creating or
re-configuring a virtual machine.

1. DmVirtualNumaNode::UpdateAssignedVpCount()
   • Before the fix the code called
     gsl::span<...>::operator[](a2) without supplying the index of the
     NUMA node that is being processed.  All callers therefore wrote
     into entry #0 of the array, irrespective of the NUMA node
     ( *(DWORD)(result+32/36) += ... ).
   • No locking or atomics were used; concurrent calls from different
     nodes raced on the same cache line and produced lost updates or
     out-of-range counts.

2. GlobalMemoryBalancer::ResourcepGetMaxLpRatio(),
   ResourcepGetBestFit(), and ResourceAssignVirtualToPhysical() used
   the same pattern: operator[] was invoked without an explicit index
   and fields at offset 32 / 36 were modified unconditionally.  The
   patch now calls operator[](span, index) and updates only one of the
   two fields (32 or 36) depending on a new feature flag
   Feature_NumaSpanningBugFix.

Because of the missing index and the absence of synchronisation, two
threads that configure different Virtual NUMA nodes can add the same
VPs to the same Resource structure, causing incorrect accounting.
Once the counters wrap or become negative, later arithmetic (e.g.
ratio calculation) divides by the wrong value and may select a
Resource that should have been considered exhausted.  That allows a
privileged guest or management application that controls VM creation
(tools running inside the partition) to over-allocate LPs, breach the
isolation guarantees and execute with elevated privileges in the host
partition.

Vulnerability Code Snippets
--------------------------------------------------------------------
```c
// before
result = gsl::span<...>::operator[](a2);      // no index
*(_DWORD *)(result + 32) += *(_DWORD *)(a1+344);
...

// after
v5 = gsl::span<...>::operator[](a2, v4);      // pass index
if ( Feature_NumaSpanningBugFix ) {
    if ( v6 )
        *(_DWORD *)(v5 + 32) += *(DWORD *)(a2+32) * v6;
} else {
    *(_DWORD *)(v5 + 32) += v6;
    *(_DWORD *)(v5 + 36) += *(DWORD *)(a2+32) * v6;
}
```

Trigger Flow (Top-Down)
--------------------------------------------------------------------
1. A management API (HCS / WMI / PowerShell) creates or resizes a VM
   with NUMA spanning enabled.
2. vmcompute.exe calls
   GlobalMemoryBalancer::ResourceAssignVirtualToPhysical(), which
   iterates over every VP.
3. Each VP invokes DmVirtualNumaNode::UpdateAssignedVpCount().
4. Because the shared span entry is selected incorrectly, all threads
   write into the same Resource object at the same time.
5. The resulting corrupted counters allow an attacker-controlled VM to
   obtain more LPs than authorised and to execute code with host
   privileges.

Attack Vector
--------------------------------------------------------------------
Local attacker who can create or modify a Hyper-V virtual machine (for
example, a low-privileged administrator inside a guest or a tenant in
multi-tenant hosting) races multiple configuration requests that span
across NUMA nodes to trigger the counter corruption.

Patch Description
--------------------------------------------------------------------
• All affected functions now call gsl::span::operator[](span, index),
  ensuring that each NUMA node updates its own Resource entry.
• Updates of fields at offset 32 and 36 are now mutually exclusive and
  gated by the new runtime flag
  Feature_NumaSpanningBugFix (wil-feature id 2578215227).
• The rest of the edits (signature changes in
  wil::details::ReportUsageToService and its callers) are telemetry
  only and do not affect the vulnerability.

Security Impact
--------------------------------------------------------------------
Before the fix concurrent configuration of NUMA-spanning VMs could
corrupt shared accounting data, allowing over-allocation of logical
processors and breaking isolation barriers between guest and host.
An attacker with VM-management privileges could leverage the race to
run code with elevated (host) privileges – an elevation-of-privilege
(EoP) scenario.

Fix Effectiveness
--------------------------------------------------------------------
The patch eliminates the data race by writing to the correct Resource
slot and by avoiding duplicate counter increments.  No additional
locking was introduced; correctness now relies on each thread using
its own slot, which removes the previously shared write path.  If all
callers pass the proper index this fully mitigates the identified
issue; residual risk is considered low.
